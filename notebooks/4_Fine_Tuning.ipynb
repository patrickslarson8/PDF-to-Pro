{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Finetune the Model\n",
    "Step 4 is to actually fine-tune the model on the question/answer pairs."
   ],
   "id": "fea5dcfcb5b2fc84"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Environment Setup\n",
    "\n",
    "This step uses the following libraries:\n",
    "|Library|License|\n",
    "|-|-|\n",
    "| [PyTorch](https://github.com/pytorch/pytorch) | BSD 3-Clause |\n",
    "| [python-dotenv](https://github.com/theskumar/python-dotenv) | BSD 3-Clause |\n",
    "| [transformers](https://github.com/huggingface/transformers) | Apache 2.0 |\n",
    "| [datasets](https://github.com/huggingface/datasets) | Apache 2.0 |\n",
    "| [trl](https://github.com/huggingface/trl) | Apache 2.0 |\n",
    "| [peft](https://github.com/huggingface/peft) | Apache 2.0 |\n",
    "| [evaluate](https://github.com/huggingface/evaluate) | Apache 2.0 |\n",
    "| [bert_score](https://github.com/Tiiiger/bert_score) | MIT |\n",
    "| [numpy](https://numpy.org/about/) | Modified BSD |"
   ],
   "id": "f103cc9ef94abcc2"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:07.292888Z",
     "start_time": "2025-05-22T22:01:04.633959Z"
    }
   },
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from trl import DataCollatorForCompletionOnlyLM\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    EarlyStoppingCallback)\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import evaluate"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:07.372023Z",
     "start_time": "2025-05-22T22:01:07.370014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DOCUMENT    = \"FM5_0\"\n",
    "PDF_PATH    = Path(\"pdfs/raw/fm5-0.pdf\")\n",
    "BASE_MODEL  = Path(\"QuantFactory/Llama-3.2-1B-GGUF\")\n",
    "GGUF_FILE   = \"Llama-3.2-1B.Q8_0.gguf\"\n",
    "CACHE_DIR   = \"hf_cache\"\n",
    "DATA_DIR    = DOCUMENT / BASE_MODEL / \"data\"\n",
    "MODEL_DIR   = DOCUMENT / BASE_MODEL / \"lora\"\n",
    "CHUNKED_DATA = DATA_DIR / \"chunked\" / \"chunked.jsonl\"\n",
    "QA_DATA      = DATA_DIR / \"qa\"       / \"qa_pairs.jsonl\"\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ],
   "id": "10d8d56c9a612a4e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load the dataset and get the tokenizers ready.",
   "id": "329fd97f3b2f2a5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:07.914878Z",
     "start_time": "2025-05-22T22:01:07.419621Z"
    }
   },
   "cell_type": "code",
   "source": "raw_ds = load_dataset(\"json\", data_files=QA_DATA.as_posix(), split=\"train\")",
   "id": "718e022547800751",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:08.225227Z",
     "start_time": "2025-05-22T22:01:07.921436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tok              = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "tok.pad_token    = \"<|finetune_right_pad_id|>\"\n",
    "tok.pad_token_id = tok.convert_tokens_to_ids(tok.pad_token)\n",
    "\n",
    "# pred_tok              = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "# pred_tok.pad_token    = \"<|finetune_right_pad_id|>\"\n",
    "# pred_tok.padding_side = \"left\""
   ],
   "id": "134d5b8ca697ea59",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Configure our model.",
   "id": "78c0a743ade6b78b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:08.245262Z",
     "start_time": "2025-05-22T22:01:08.242959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TEST_PORTION = 0.1\n",
    "IGNORE_ID    = -100\n",
    "MAX_LEN      = 1024"
   ],
   "id": "34e4e9e3348a2461",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:08.301028Z",
     "start_time": "2025-05-22T22:01:08.299463Z"
    }
   },
   "cell_type": "code",
   "source": "sys_prompt = f\" You are an FM-5-0 assistant. Concisely answer the following question.\"",
   "id": "da0a0a467b6c851b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:08.359423Z",
     "start_time": "2025-05-22T22:01:08.357711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sys_role = \"system\"\n",
    "usr_role = \"user\"\n",
    "bot_role = \"assistant\""
   ],
   "id": "24d3b16c03e599c9",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:08.433306Z",
     "start_time": "2025-05-22T22:01:08.431468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bos_tok      = \"<|begin_of_text|>\"\n",
    "eot_id_tok   = \"<|eot_id|>\"\n",
    "start_hd_tok = \"<|start_header_id|>\"\n",
    "end_hd_tok   = \"<|end_header_id|>\"\n",
    "eot_tok      = \"<|end_of_text|>\""
   ],
   "id": "c6c917c375c565dd",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define some functions to process the data so we can train on it.",
   "id": "dcccbd03a0511c27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:08.496717Z",
     "start_time": "2025-05-22T22:01:08.494306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_prompt(sys, context, usr, ans=None):\n",
    "    prompt  = f\"{bos_tok}\"\n",
    "    prompt += f\"{start_hd_tok}{sys_role}{end_hd_tok}{context}{sys}{eot_id_tok}\"\n",
    "    prompt += f\"{start_hd_tok}{usr_role}{end_hd_tok}{usr}{eot_id_tok}\"\n",
    "    prompt += f\"{start_hd_tok}{bot_role}{end_hd_tok}\"\n",
    "\n",
    "    if ans is not None:\n",
    "        prompt += f\"{ans}{eot_id_tok}{eot_tok}\"\n",
    "\n",
    "    return prompt"
   ],
   "id": "80c26f524210411c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:08.555466Z",
     "start_time": "2025-05-22T22:01:08.553766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def row_to_prompt(row):\n",
    "    return {\"text\": build_prompt(sys_prompt, row['context'], row['question'], ans=row['answer'])}"
   ],
   "id": "23a4a0c2cba9230a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now process the data. I'll start with one sample to see how it's handled through the collator and evaluations.",
   "id": "34114a5a1f8a0bc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:22:33.844027Z",
     "start_time": "2025-05-22T22:22:33.838165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "splits  = prompt_ds.train_test_split(TEST_PORTION, seed=42)\n",
    "sample = splits[\"train\"][100]\n",
    "print(sample)"
   ],
   "id": "27a063ac0592f5b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>The  division  tactical  command  post  will  control  the  air assault').\\n- b. (U) Signal. Describe the scheme of signal support, including location and movement of key signal nodes and critical electromagnetic spectrum considerations throughout the operation. State the primary, alternate, contingency, and emergency communications plan. Refer to Annex H (Signal) as required.\\n\\nACKNOWLEDGE: Include only if attachment is distributed separately from the base order.\\n\\n[Commander's last name]\\n\\n[Commander's rank]\\n\\nThe commander or authorized representative signs the original copy of the attachment. If the representative signs the original, add the phrase 'For the Commander.' The signed copy is the historical copy and remains in the headquarters' files.\\n\\n## OFFICIAL:\\n\\n[Authenticator's name]\\n\\n[Authenticator's position]\\n\\nUse only if the commander does not sign the original attachment. If the commander signs the original, no further authentication is required. If the commander does not sign, the signature of the preparing staff officer requires authentication and only the last name and rank of the commander appear in the signature block.\\n\\nATTACHMENTS: List lower-level attachment (appendixes, tabs, and exhibits). If a particular attachment is not used, place 'not used' beside the attachment number. Unit standard operating procedures will dictate attachment development and format. Common attachments include the following:\\n\\nAppendix 1 - Concept of Signal Support Overlay.\\n\\n- Appendix 2 - Department of Defense Information Network Operations.\\n- Appendix 3 - Network Transport and Information Services.\\n- Appendix 4 - Spectrum Management Operations.\\n- Appendix 5 - Communications Security.\\n\\nDISTRIBUTION: Show only if distributed separately from the base order or higher-level attachments.\\n\\n## [page number] [CLASSIFICATION]\\n\\nFigure E-8. Sample Annex H (Signal) format (continued)\\n\\n## ANNEX I (AIR AND MISSILE DEFENSE) FORMAT AND INSTRUCTIONS\\n\\n- E-43. This annex provides fundamental considerations, formats, and instructions for developing Annex I (Air and Missile Defense) to the base plan or order. This annex follows the five-paragraph attachment format.\\n- E-44. Commanders and staffs use Annex I (Air and Missile Defense) to describe how air defense supports the concept of operations described in the base plan or order. The supporting air defense artillery commander in  coordination  with  the You are an FM-5-0 assistant. Concisely answer the following question.<|eot_id|><|start_header_id|>user<|end_header_id|>What does Annex I (Air and Missile Defense) provide?<|eot_id|><|start_header_id|>assistant<|end_header_id|>This annex provides fundamental considerations, formats, and instructions for developing Annex I (Air and Missile Defense) to the base plan or order.<|eot_id|><|end_of_text|>\"}\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:57:18.042525Z",
     "start_time": "2025-05-22T22:57:18.038431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tok.add_bos_token = False\n",
    "tokenised = tok(\n",
    "    sample[\"text\"],        # or whatever field you use\n",
    "    max_length=1024,\n",
    "    truncation=True,\n",
    ")\n",
    "\n",
    "print(\"IDS IN   :\", tokenised[\"input_ids\"][:40])\n",
    "print(\"MASK     :\", tokenised[\"attention_mask\"][:40])\n",
    "print(\"TOKENS IN:\", tok.convert_ids_to_tokens(tokenised[\"input_ids\"][:40]))\n",
    "print(\"TOKENS IN:\", tok.decode(tokenised[\"input_ids\"][:40], clean_up_tokenization_spaces=True))"
   ],
   "id": "484ebd44986702d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDS IN   : [128000, 128006, 9125, 128007, 791, 220, 13096, 220, 39747, 220, 3290, 220, 1772, 220, 690, 220, 2585, 220, 279, 220, 3805, 11965, 1861, 198, 12, 293, 13, 320, 52, 8, 28329, 13, 61885, 279, 13155, 315, 8450, 1862, 11, 2737]\n",
      "MASK     : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "TOKENS IN: ['<|begin_of_text|>', '<|start_header_id|>', 'system', '<|end_header_id|>', 'The', 'Ġ', 'Ġdivision', 'Ġ', 'Ġtactical', 'Ġ', 'Ġcommand', 'Ġ', 'Ġpost', 'Ġ', 'Ġwill', 'Ġ', 'Ġcontrol', 'Ġ', 'Ġthe', 'Ġ', 'Ġair', 'Ġassault', \"').\", 'Ċ', '-', 'Ġb', '.', 'Ġ(', 'U', ')', 'ĠSignal', '.', 'ĠDescribe', 'Ġthe', 'Ġscheme', 'Ġof', 'Ġsignal', 'Ġsupport', ',', 'Ġincluding']\n",
      "TOKENS IN: <|begin_of_text|><|start_header_id|>system<|end_header_id|>The  division  tactical  command  post  will  control  the  air assault').\n",
      "- b. (U) Signal. Describe the scheme of signal support, including\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:58:10.640596Z",
     "start_time": "2025-05-22T22:58:10.636852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "collator = DataCollatorForCompletionOnlyLM(\n",
    "    tokenizer            = tok,\n",
    "    instruction_template = f\"{start_hd_tok}{usr_role}{end_hd_tok}\",\n",
    "    response_template    = f\"{start_hd_tok}{bot_role}{end_hd_tok}\",\n",
    ")"
   ],
   "id": "26eadf5391bcfb6e",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:58:13.378385Z",
     "start_time": "2025-05-22T22:58:13.373645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch = collator([tokenised])            # batch size 1 on purpose\n",
    "for k,v in batch.items():\n",
    "    print(k, v.shape, v[0][:40])"
   ],
   "id": "e57d27eb89f8769e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([1, 583]) tensor([128000, 128006,   9125, 128007,    791,    220,  13096,    220,  39747,\n",
      "           220,   3290,    220,   1772,    220,    690,    220,   2585,    220,\n",
      "           279,    220,   3805,  11965,   1861,    198,     12,    293,     13,\n",
      "           320,     52,      8,  28329,     13,  61885,    279,  13155,    315,\n",
      "          8450,   1862,     11,   2737])\n",
      "attention_mask torch.Size([1, 583]) tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "labels torch.Size([1, 583]) tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100])\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T23:26:31.943179Z",
     "start_time": "2025-05-22T23:26:31.937799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for k,v in batch.items():\n",
    "    print(k, v.shape, v[0][-40:])"
   ],
   "id": "98f5ae98bf61a5a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([1, 583]) tensor([ 26777,    323,  68870,  16777,      8,   3493,     30, 128009, 128006,\n",
      "         78191, 128007,   2028,  54368,   5825,  16188,  38864,     11,  20447,\n",
      "            11,    323,  11470,    369,  11469,  89720,    358,    320,  26777,\n",
      "           323,  68870,  16777,      8,    311,    279,   2385,   3197,    477,\n",
      "          2015,     13, 128009, 128001])\n",
      "attention_mask torch.Size([1, 583]) tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "labels torch.Size([1, 583]) tensor([  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   2028,  54368,   5825,  16188,  38864,     11,  20447,\n",
      "            11,    323,  11470,    369,  11469,  89720,    358,    320,  26777,\n",
      "           323,  68870,  16777,      8,    311,    279,   2385,   3197,    477,\n",
      "          2015,     13, 128009, 128001])\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T23:28:38.586038Z",
     "start_time": "2025-05-22T23:28:38.583198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels = batch[\"labels\"][0].tolist()\n",
    "last_mask_index = len(labels) - 1 - labels[::-1].index(IGNORE_ID)\n",
    "masked_label = tok.decode(labels[last_mask_index + 1:], skip_special_tokens=True)\n",
    "print(masked_label)"
   ],
   "id": "10c6fccd1fc66606",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This annex provides fundamental considerations, formats, and instructions for developing Annex I (Air and Missile Defense) to the base plan or order.\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:08.783031Z",
     "start_time": "2025-05-22T22:01:08.614450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "splits      = prompt_ds.train_test_split(TEST_PORTION, seed=42)\n",
    "text_train  = splits[\"train\"]\n",
    "text_test   = splits[\"test\"]\n",
    "\n",
    "# tok.padding_side = \"left\"\n",
    "tok_test  = splits[\"test\"].map(\n",
    "    lambda batch: tok(batch[\"text\"], add_special_tokens=False, truncation=True, max_length=MAX_LEN, padding=False),\n",
    "    batched=True)\n",
    "# tok.padding_side = \"right\"\n",
    "tok_train = splits[\"train\"].map(\n",
    "    lambda batch: tok(batch[\"text\"], add_special_tokens=False, truncation=True, max_length=MAX_LEN, padding=False),\n",
    "    batched=True)"
   ],
   "id": "dd2c930fb43b7a9d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Set up the collator which will set up the offsets for causal language models and mask our attention mask so only the answer portion is considered in the loss.",
   "id": "683ecb99379d3942"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:08.803615Z",
     "start_time": "2025-05-22T22:01:08.801120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_collator = DataCollatorForCompletionOnlyLM(\n",
    "    tokenizer            = tok,\n",
    "    instruction_template = f\"{start_hd_tok}{usr_role}{end_hd_tok}\",\n",
    "    response_template    = f\"{start_hd_tok}{bot_role}{end_hd_tok}\",\n",
    ")"
   ],
   "id": "3ca2d8205499ad27",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now we load the model and the LoRA adapter.\n",
    "\n",
    "Ideally this would be dead simple with SFTTrainer, but it doesn't support custom metrics yet (https://github.com/huggingface/trl/issues/862) so we have to do everything manually."
   ],
   "id": "92666caf9905ad1e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:33.063487Z",
     "start_time": "2025-05-22T22:01:08.861866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "            BASE_MODEL,\n",
    "            cache_dir=CACHE_DIR,\n",
    "            gguf_file=GGUF_FILE,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.bfloat16)\n",
    "base_model.gradient_checkpointing_enable()\n"
   ],
   "id": "1f7946ddf8deeb4d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Converting and de-quantizing GGUF tensors...:   0%|          | 0/147 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9639f52c6c0418486fb4a828c28e4e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:33.131963Z",
     "start_time": "2025-05-22T22:01:33.081920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lora_cfg = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\")\n",
    "lora_model = get_peft_model(base_model, lora_cfg)\n",
    "lora_model.print_trainable_parameters()  # sanity check"
   ],
   "id": "7646caf1ac6cf7fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 851,968 || all params: 1,236,666,368 || trainable%: 0.0689\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Before training, I'll set up some metrics for evaluation.\n",
    "\n",
    " - F1: This is span-wise F1 (from SQUAD) shows how well the prediction and truth match if we treat them as a \"bag of tokens\"\n",
    " - Perplexity:\n",
    " - BLUERT: Would like to sue, but omitted due to installation complexity (native TensorFlow implementation)\n",
    " - BERT Score:"
   ],
   "id": "5fb597a4e9e1a0f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:02:45.390012Z",
     "start_time": "2025-05-22T22:02:06.633746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bert_metric   = evaluate.load(\"bertscore\", cache_dir=CACHE_DIR)\n",
    "squad_metric  = evaluate.load(\"squad\", cache_dir=CACHE_DIR)"
   ],
   "id": "53d37749346972df",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:02:47.660268Z",
     "start_time": "2025-05-22T22:02:47.649218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_preds) -> dict:\n",
    "    preds  = eval_preds.predictions\n",
    "    labels = eval_preds.label_ids\n",
    "    losses = eval_preds.losses\n",
    "\n",
    "    cleaned_labels = np.where(labels != IGNORE_ID, labels, tok.pad_token_id)\n",
    "    cleaned_preds  = np.where(preds  != IGNORE_ID, preds,  tok.pad_token_id)\n",
    "\n",
    "    # tok.padding_side = \"left\"\n",
    "    decoded_preds  = tok.batch_decode(cleaned_preds.tolist(), skip_special_tokens=True)\n",
    "    decoded_labels = tok.batch_decode(cleaned_labels.tolist(), skip_special_tokens=True)\n",
    "    # tok.padding_side = \"right\"\n",
    "\n",
    "    squad_preds = [\n",
    "        {\"id\": str(i), \"prediction_text\": p}\n",
    "        for i, p in enumerate(decoded_preds)\n",
    "    ]\n",
    "    squad_refs = [\n",
    "        {\n",
    "            \"id\": str(i),\n",
    "            \"answers\": {\"text\": [decoded_labels[i]], \"answer_start\": [0]}\n",
    "        }\n",
    "        for i in range(len(decoded_labels))\n",
    "    ]\n",
    "    squad_results = squad_metric.compute(\n",
    "        predictions=squad_preds,\n",
    "        references=squad_refs\n",
    "    )\n",
    "\n",
    "    bert_results = bert_metric.compute(\n",
    "        predictions=decoded_preds,\n",
    "        references=decoded_labels,\n",
    "        lang=\"en\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"perplexity\":      np.mean(np.exp(losses)),\n",
    "        \"bert_precision\":  np.mean(bert_results[\"precision\"]),\n",
    "        \"bert_recall\":     np.mean(bert_results[\"recall\"]),\n",
    "        \"bert_f1\":         np.mean(bert_results[\"f1\"]),\n",
    "        \"qa_f1\":           squad_results[\"f1\"],\n",
    "        \"exact_match\":     squad_results[\"exact_match\"],\n",
    "    }"
   ],
   "id": "4872268a6e5fdd6a",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:03:21.982330Z",
     "start_time": "2025-05-22T22:02:55.809454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir                  = MODEL_DIR,\n",
    "    per_device_train_batch_size = 2,\n",
    "    gradient_accumulation_steps = 32,\n",
    "    num_train_epochs            = 10,\n",
    "    learning_rate               = 2e-4,\n",
    "    logging_steps               = 1,\n",
    "    save_steps                  = 1,\n",
    "    save_total_limit            = 10,\n",
    "    neftune_noise_alpha         = 0.1,\n",
    "    bf16                        = True,\n",
    "    bf16_full_eval              = True,\n",
    "    save_strategy               = \"epoch\",\n",
    "    eval_strategy               = \"epoch\",\n",
    "    report_to                   = \"none\",\n",
    "    label_names                 = [\"labels\"],\n",
    "    metric_for_best_model       = \"eval_loss\",\n",
    "    load_best_model_at_end      = True,\n",
    "    eval_on_start               = True,\n",
    "    eval_accumulation_steps     = 10,\n",
    "    include_for_metrics         = [\"loss\"],\n",
    "    predict_with_generate       = True,\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStoppingCallback(\n",
    "    early_stopping_patience  = 1,\n",
    "    early_stopping_threshold = 0.001,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model           = lora_model,\n",
    "    args            = args,\n",
    "    train_dataset   = tok_train,\n",
    "    eval_dataset    = tok_test,\n",
    "    data_collator   = data_collator,\n",
    "    callbacks       = [early_stopping],\n",
    "    compute_metrics = compute_metrics,\n",
    ")"
   ],
   "id": "ba1335d4a0043888",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:11:49.591912Z",
     "start_time": "2025-05-22T22:03:30.149894Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "1396f499eeef5dca",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='None' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      None\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:07]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[19]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/transformers/trainer.py:2245\u001B[39m, in \u001B[36mTrainer.train\u001B[39m\u001B[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[39m\n\u001B[32m   2243\u001B[39m         hf_hub_utils.enable_progress_bars()\n\u001B[32m   2244\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2245\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2246\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2247\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2248\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2249\u001B[39m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2250\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/transformers/trainer.py:2472\u001B[39m, in \u001B[36mTrainer._inner_training_loop\u001B[39m\u001B[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[39m\n\u001B[32m   2469\u001B[39m \u001B[38;5;28mself\u001B[39m.control = \u001B[38;5;28mself\u001B[39m.callback_handler.on_train_begin(args, \u001B[38;5;28mself\u001B[39m.state, \u001B[38;5;28mself\u001B[39m.control)\n\u001B[32m   2471\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m args.eval_on_start:\n\u001B[32m-> \u001B[39m\u001B[32m2472\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskip_scheduler\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m   2474\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs_trained, num_train_epochs):\n\u001B[32m   2475\u001B[39m     epoch_dataloader = train_dataloader\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/transformers/trainer.py:3045\u001B[39m, in \u001B[36mTrainer._evaluate\u001B[39m\u001B[34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001B[39m\n\u001B[32m   3044\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_evaluate\u001B[39m(\u001B[38;5;28mself\u001B[39m, trial, ignore_keys_for_eval, skip_scheduler=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m-> \u001B[39m\u001B[32m3045\u001B[39m     metrics = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3046\u001B[39m     \u001B[38;5;28mself\u001B[39m._report_to_hp_search(trial, \u001B[38;5;28mself\u001B[39m.state.global_step, metrics)\n\u001B[32m   3048\u001B[39m     \u001B[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/transformers/trainer_seq2seq.py:197\u001B[39m, in \u001B[36mSeq2SeqTrainer.evaluate\u001B[39m\u001B[34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001B[39m\n\u001B[32m    195\u001B[39m \u001B[38;5;28mself\u001B[39m.gather_function = \u001B[38;5;28mself\u001B[39m.accelerator.gather\n\u001B[32m    196\u001B[39m \u001B[38;5;28mself\u001B[39m._gen_kwargs = gen_kwargs\n\u001B[32m--> \u001B[39m\u001B[32m197\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43meval_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/transformers/trainer.py:4154\u001B[39m, in \u001B[36mTrainer.evaluate\u001B[39m\u001B[34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001B[39m\n\u001B[32m   4151\u001B[39m start_time = time.time()\n\u001B[32m   4153\u001B[39m eval_loop = \u001B[38;5;28mself\u001B[39m.prediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.use_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.evaluation_loop\n\u001B[32m-> \u001B[39m\u001B[32m4154\u001B[39m output = \u001B[43meval_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4155\u001B[39m \u001B[43m    \u001B[49m\u001B[43meval_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4156\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mEvaluation\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   4157\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001B[39;49;00m\n\u001B[32m   4158\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# self.args.prediction_loss_only\u001B[39;49;00m\n\u001B[32m   4159\u001B[39m \u001B[43m    \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   4160\u001B[39m \u001B[43m    \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4161\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4162\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4164\u001B[39m total_batch_size = \u001B[38;5;28mself\u001B[39m.args.eval_batch_size * \u001B[38;5;28mself\u001B[39m.args.world_size\n\u001B[32m   4165\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_key_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_jit_compilation_time\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output.metrics:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/transformers/trainer.py:4443\u001B[39m, in \u001B[36mTrainer.evaluation_loop\u001B[39m\u001B[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[39m\n\u001B[32m   4441\u001B[39m     eval_set_kwargs[\u001B[33m\"\u001B[39m\u001B[33mlosses\u001B[39m\u001B[33m\"\u001B[39m] = all_losses \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mloss\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m args.include_for_metrics \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   4442\u001B[39m     eval_set_kwargs[\u001B[33m\"\u001B[39m\u001B[33minputs\u001B[39m\u001B[33m\"\u001B[39m] = all_inputs \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33minputs\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m args.include_for_metrics \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m4443\u001B[39m     metrics = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4444\u001B[39m \u001B[43m        \u001B[49m\u001B[43mEvalPrediction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mall_preds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mall_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43meval_set_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4445\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4446\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m metrics \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   4447\u001B[39m     metrics = {}\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 14\u001B[39m, in \u001B[36mcompute_metrics\u001B[39m\u001B[34m(eval_preds)\u001B[39m\n\u001B[32m     11\u001B[39m decoded_labels = tok.batch_decode(cleaned_labels.tolist(), skip_special_tokens=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m     12\u001B[39m \u001B[38;5;66;03m# tok.padding_side = \"right\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m squad_preds = \u001B[43m[\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[43m    \u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mid\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mprediction_text\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m}\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdecoded_preds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     17\u001B[39m \u001B[43m\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m     18\u001B[39m squad_refs = [\n\u001B[32m     19\u001B[39m     {\n\u001B[32m     20\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mid\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mstr\u001B[39m(i),\n\u001B[32m   (...)\u001B[39m\u001B[32m     23\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(decoded_labels))\n\u001B[32m     24\u001B[39m ]\n\u001B[32m     25\u001B[39m squad_results = squad_metric.compute(\n\u001B[32m     26\u001B[39m     predictions=squad_preds,\n\u001B[32m     27\u001B[39m     references=squad_refs\n\u001B[32m     28\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/JetBrains/Toolbox/apps/pycharm/plugins/python-ce/helpers/pydev/_pydevd_bundle/pydevd_frame.py:755\u001B[39m, in \u001B[36mPyDBFrame.trace_dispatch\u001B[39m\u001B[34m(self, frame, event, arg)\u001B[39m\n\u001B[32m    753\u001B[39m \u001B[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001B[39;00m\n\u001B[32m    754\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m info.pydev_state == STATE_SUSPEND:\n\u001B[32m--> \u001B[39m\u001B[32m755\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    756\u001B[39m     \u001B[38;5;66;03m# No need to reset frame.f_trace to keep the same trace function.\u001B[39;00m\n\u001B[32m    757\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.trace_dispatch\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/JetBrains/Toolbox/apps/pycharm/plugins/python-ce/helpers/pydev/_pydevd_bundle/pydevd_frame.py:412\u001B[39m, in \u001B[36mPyDBFrame.do_wait_suspend\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    411\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdo_wait_suspend\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m412\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_args\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/JetBrains/Toolbox/apps/pycharm/plugins/python-ce/helpers/pydev/pydevd.py:1220\u001B[39m, in \u001B[36mPyDB.do_wait_suspend\u001B[39m\u001B[34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[39m\n\u001B[32m   1217\u001B[39m         from_this_thread.append(frame_id)\n\u001B[32m   1219\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._threads_suspended_single_notification.notify_thread_suspended(thread_id, stop_reason):\n\u001B[32m-> \u001B[39m\u001B[32m1220\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/JetBrains/Toolbox/apps/pycharm/plugins/python-ce/helpers/pydev/pydevd.py:1235\u001B[39m, in \u001B[36mPyDB._do_wait_suspend\u001B[39m\u001B[34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[39m\n\u001B[32m   1232\u001B[39m             \u001B[38;5;28mself\u001B[39m._call_mpl_hook()\n\u001B[32m   1234\u001B[39m         \u001B[38;5;28mself\u001B[39m.process_internal_commands()\n\u001B[32m-> \u001B[39m\u001B[32m1235\u001B[39m         \u001B[43mtime\u001B[49m\u001B[43m.\u001B[49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1237\u001B[39m \u001B[38;5;28mself\u001B[39m.cancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[32m   1239\u001B[39m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4c9a0a39dde07ece",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# lora_model.save_pretrained(\"ft-rag-qa\")\n",
    "# tok.save_pretrained(\"ft-rag-qa\")"
   ],
   "id": "a1f912139eca0ddb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "usr = \"What are the two categories of CCIRs?\"\n",
    "context  = \"\" # or retrieved chunk text (hopefully) containing the answer\n",
    "\n",
    "prompt =  build_prompt(sys_prompt, context, usr)\n",
    "\n",
    "inputs = tok(prompt, return_tensors=\"pt\").to(lora_model.device)\n",
    "out = lora_model.generate(**inputs, max_new_tokens=512, temperature=0.2)\n",
    "print(tok.decode(out[0][inputs.input_ids.shape[-1]:], skip_special_tokens=False))"
   ],
   "id": "47add3b7c5680270",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
