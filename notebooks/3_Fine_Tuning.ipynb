{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Finetune the Model",
   "id": "fea5dcfcb5b2fc84"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Environment Setup\n",
    "\n",
    "This step uses the following libraries:\n",
    "|Library|License|\n",
    "|-|-|\n",
    "| [PyTorch](https://github.com/pytorch/pytorch) | BSD 3-Clause |\n",
    "| [python-dotenv](https://github.com/theskumar/python-dotenv) | BSD 3-Clause |\n",
    "| [transformers](https://github.com/huggingface/transformers) | Apache 2.0 |\n",
    "| [datasets](https://github.com/huggingface/datasets) | Apache 2.0 |\n",
    "| [trl](https://github.com/huggingface/trl) | Apache 2.0 |\n",
    "| [peft](https://github.com/huggingface/peft) | Apache 2.0 |\n",
    "| [evaluate](https://github.com/huggingface/evaluate) | Apache 2.0 |\n",
    "| [bert_score](https://github.com/Tiiiger/bert_score) | MIT |\n",
    "| [numpy](https://numpy.org/about/) | Modified BSD |"
   ],
   "id": "f103cc9ef94abcc2"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-25T21:52:41.087358Z",
     "start_time": "2025-05-25T21:52:41.083797Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from trl import DataCollatorForCompletionOnlyLM\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    EarlyStoppingCallback)\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import evaluate"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T21:52:41.734311Z",
     "start_time": "2025-05-25T21:52:41.731437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DOCUMENT    = \"FM5_0\"\n",
    "PDF_PATH    = Path(\"pdfs/raw/fm5-0.pdf\")\n",
    "BASE_MODEL  = Path(\"QuantFactory/Llama-3.2-1B-GGUF\")\n",
    "GGUF_FILE   = \"Llama-3.2-1B.Q8_0.gguf\"\n",
    "CACHE_DIR   = \"hf_cache\"\n",
    "DATA_DIR    = DOCUMENT / BASE_MODEL / \"data\"\n",
    "MODEL_DIR   = DOCUMENT / BASE_MODEL / \"lora\"\n",
    "CHUNKED_DATA = DATA_DIR / \"chunked\" / \"chunked.jsonl\"\n",
    "QA_DATA      = DATA_DIR / \"qa\"       / \"qa_pairs.jsonl\"\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ],
   "id": "10d8d56c9a612a4e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load the dataset and get the tokenizers ready.",
   "id": "329fd97f3b2f2a5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T21:52:45.314959Z",
     "start_time": "2025-05-25T21:52:44.448130Z"
    }
   },
   "cell_type": "code",
   "source": "raw_ds = load_dataset(\"json\", data_files=QA_DATA.as_posix(), split=\"train\")",
   "id": "718e022547800751",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9573912f75b6421c87c8ccab4bdb7a12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load JSON from file '/home/pat/PycharmProjects/DunedainAssessment/notebooks/FM5_0/QuantFactory/Llama-3.2-1B-GGUF/data/qa/qa_pairs.jsonl' with error <class 'pyarrow.lib.ArrowInvalid'>: JSON parse error: Column() changed from object to string in row 0\n"
     ]
    },
    {
     "ename": "DatasetGenerationError",
     "evalue": "An error occurred while generating the dataset",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/datasets/packaged_modules/json/json.py:160\u001B[39m, in \u001B[36mJson._generate_tables\u001B[39m\u001B[34m(self, files)\u001B[39m\n\u001B[32m    157\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\n\u001B[32m    158\u001B[39m         file, encoding=\u001B[38;5;28mself\u001B[39m.config.encoding, errors=\u001B[38;5;28mself\u001B[39m.config.encoding_errors\n\u001B[32m    159\u001B[39m     ) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m--> \u001B[39m\u001B[32m160\u001B[39m         df = \u001B[43mpandas_read_json\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    161\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/datasets/packaged_modules/json/json.py:38\u001B[39m, in \u001B[36mpandas_read_json\u001B[39m\u001B[34m(path_or_buf, **kwargs)\u001B[39m\n\u001B[32m     37\u001B[39m     kwargs[\u001B[33m\"\u001B[39m\u001B[33mdtype_backend\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[33m\"\u001B[39m\u001B[33mpyarrow\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m38\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_json\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_or_buf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/pandas/io/json/_json.py:815\u001B[39m, in \u001B[36mread_json\u001B[39m\u001B[34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001B[39m\n\u001B[32m    814\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m815\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mjson_reader\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/pandas/io/json/_json.py:1025\u001B[39m, in \u001B[36mJsonReader.read\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1024\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1025\u001B[39m     obj = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_object_parser\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1026\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.dtype_backend \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m lib.no_default:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/pandas/io/json/_json.py:1051\u001B[39m, in \u001B[36mJsonReader._get_object_parser\u001B[39m\u001B[34m(self, json)\u001B[39m\n\u001B[32m   1050\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m typ == \u001B[33m\"\u001B[39m\u001B[33mframe\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m1051\u001B[39m     obj = \u001B[43mFrameParser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1053\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m typ == \u001B[33m\"\u001B[39m\u001B[33mseries\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/pandas/io/json/_json.py:1187\u001B[39m, in \u001B[36mParser.parse\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1185\u001B[39m \u001B[38;5;129m@final\u001B[39m\n\u001B[32m   1186\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mparse\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m-> \u001B[39m\u001B[32m1187\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_parse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1189\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/pandas/io/json/_json.py:1403\u001B[39m, in \u001B[36mFrameParser._parse\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1401\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m orient == \u001B[33m\"\u001B[39m\u001B[33mcolumns\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m   1402\u001B[39m     \u001B[38;5;28mself\u001B[39m.obj = DataFrame(\n\u001B[32m-> \u001B[39m\u001B[32m1403\u001B[39m         \u001B[43mujson_loads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprecise_float\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mprecise_float\u001B[49m\u001B[43m)\u001B[49m, dtype=\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1404\u001B[39m     )\n\u001B[32m   1405\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m orient == \u001B[33m\"\u001B[39m\u001B[33msplit\u001B[39m\u001B[33m\"\u001B[39m:\n",
      "\u001B[31mValueError\u001B[39m: Trailing data",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mArrowInvalid\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/datasets/builder.py:1855\u001B[39m, in \u001B[36mArrowBasedBuilder._prepare_split_single\u001B[39m\u001B[34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001B[39m\n\u001B[32m   1854\u001B[39m _time = time.time()\n\u001B[32m-> \u001B[39m\u001B[32m1855\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtable\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   1856\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmax_shard_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mwriter\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_num_bytes\u001B[49m\u001B[43m \u001B[49m\u001B[43m>\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_shard_size\u001B[49m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/datasets/packaged_modules/json/json.py:163\u001B[39m, in \u001B[36mJson._generate_tables\u001B[39m\u001B[34m(self, files)\u001B[39m\n\u001B[32m    162\u001B[39m     logger.error(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFailed to load JSON from file \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m with error \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(e)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m163\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[32m    164\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m df.columns.tolist() == [\u001B[32m0\u001B[39m]:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/datasets/packaged_modules/json/json.py:137\u001B[39m, in \u001B[36mJson._generate_tables\u001B[39m\u001B[34m(self, files)\u001B[39m\n\u001B[32m    136\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m137\u001B[39m     pa_table = \u001B[43mpaj\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_json\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    138\u001B[39m \u001B[43m        \u001B[49m\u001B[43mio\u001B[49m\u001B[43m.\u001B[49m\u001B[43mBytesIO\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mread_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpaj\u001B[49m\u001B[43m.\u001B[49m\u001B[43mReadOptions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblock_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mblock_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    139\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    140\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/pyarrow/_json.pyx:342\u001B[39m, in \u001B[36mpyarrow._json.read_json\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/pyarrow/error.pxi:155\u001B[39m, in \u001B[36mpyarrow.lib.pyarrow_internal_check_status\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/pyarrow/error.pxi:92\u001B[39m, in \u001B[36mpyarrow.lib.check_status\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mArrowInvalid\u001B[39m: JSON parse error: Column() changed from object to string in row 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mDatasetGenerationError\u001B[39m                    Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m raw_ds = \u001B[43mload_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mjson\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_files\u001B[49m\u001B[43m=\u001B[49m\u001B[43mQA_DATA\u001B[49m\u001B[43m.\u001B[49m\u001B[43mas_posix\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtrain\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/datasets/load.py:2084\u001B[39m, in \u001B[36mload_dataset\u001B[39m\u001B[34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001B[39m\n\u001B[32m   2081\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m builder_instance.as_streaming_dataset(split=split)\n\u001B[32m   2083\u001B[39m \u001B[38;5;66;03m# Download and prepare data\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2084\u001B[39m \u001B[43mbuilder_instance\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdownload_and_prepare\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2085\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdownload_config\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdownload_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2086\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdownload_mode\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdownload_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2087\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverification_mode\u001B[49m\u001B[43m=\u001B[49m\u001B[43mverification_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2088\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_proc\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnum_proc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2089\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2090\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2092\u001B[39m \u001B[38;5;66;03m# Build dataset for splits\u001B[39;00m\n\u001B[32m   2093\u001B[39m keep_in_memory = (\n\u001B[32m   2094\u001B[39m     keep_in_memory \u001B[38;5;28;01mif\u001B[39;00m keep_in_memory \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m is_small_dataset(builder_instance.info.dataset_size)\n\u001B[32m   2095\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/datasets/builder.py:925\u001B[39m, in \u001B[36mDatasetBuilder.download_and_prepare\u001B[39m\u001B[34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001B[39m\n\u001B[32m    923\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m num_proc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    924\u001B[39m     prepare_split_kwargs[\u001B[33m\"\u001B[39m\u001B[33mnum_proc\u001B[39m\u001B[33m\"\u001B[39m] = num_proc\n\u001B[32m--> \u001B[39m\u001B[32m925\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_download_and_prepare\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    926\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdl_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdl_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    927\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverification_mode\u001B[49m\u001B[43m=\u001B[49m\u001B[43mverification_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    928\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mprepare_split_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    929\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mdownload_and_prepare_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    930\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    931\u001B[39m \u001B[38;5;66;03m# Sync info\u001B[39;00m\n\u001B[32m    932\u001B[39m \u001B[38;5;28mself\u001B[39m.info.dataset_size = \u001B[38;5;28msum\u001B[39m(split.num_bytes \u001B[38;5;28;01mfor\u001B[39;00m split \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.info.splits.values())\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/datasets/builder.py:1001\u001B[39m, in \u001B[36mDatasetBuilder._download_and_prepare\u001B[39m\u001B[34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001B[39m\n\u001B[32m    997\u001B[39m split_dict.add(split_generator.split_info)\n\u001B[32m    999\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1000\u001B[39m     \u001B[38;5;66;03m# Prepare split will record examples associated to the split\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1001\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_prepare_split\u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_generator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mprepare_split_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1002\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m   1003\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\n\u001B[32m   1004\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mCannot find data file. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1005\u001B[39m         + (\u001B[38;5;28mself\u001B[39m.manual_download_instructions \u001B[38;5;129;01mor\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   1006\u001B[39m         + \u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mOriginal error:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m   1007\u001B[39m         + \u001B[38;5;28mstr\u001B[39m(e)\n\u001B[32m   1008\u001B[39m     ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/datasets/builder.py:1742\u001B[39m, in \u001B[36mArrowBasedBuilder._prepare_split\u001B[39m\u001B[34m(self, split_generator, file_format, num_proc, max_shard_size)\u001B[39m\n\u001B[32m   1740\u001B[39m job_id = \u001B[32m0\u001B[39m\n\u001B[32m   1741\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m pbar:\n\u001B[32m-> \u001B[39m\u001B[32m1742\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mjob_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdone\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontent\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_prepare_split_single\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1743\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgen_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgen_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjob_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mjob_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43m_prepare_split_args\u001B[49m\n\u001B[32m   1744\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   1745\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdone\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   1746\u001B[39m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontent\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/datasets/builder.py:1898\u001B[39m, in \u001B[36mArrowBasedBuilder._prepare_split_single\u001B[39m\u001B[34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001B[39m\n\u001B[32m   1896\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e, DatasetGenerationError):\n\u001B[32m   1897\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1898\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m DatasetGenerationError(\u001B[33m\"\u001B[39m\u001B[33mAn error occurred while generating the dataset\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01me\u001B[39;00m\n\u001B[32m   1900\u001B[39m \u001B[38;5;28;01myield\u001B[39;00m job_id, \u001B[38;5;28;01mTrue\u001B[39;00m, (total_num_examples, total_num_bytes, writer._features, num_shards, shard_lengths)\n",
      "\u001B[31mDatasetGenerationError\u001B[39m: An error occurred while generating the dataset"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:08.225227Z",
     "start_time": "2025-05-22T22:01:07.921436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tok              = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "# tok.pad_token    = \"<|finetune_right_pad_id|>\"\n",
    "# tok.pad_token_id = tok.convert_tokens_to_ids(tok.pad_token)"
   ],
   "id": "134d5b8ca697ea59",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Configure the model.",
   "id": "78c0a743ade6b78b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:08.245262Z",
     "start_time": "2025-05-22T22:01:08.242959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TEST_PORTION = 0.1\n",
    "IGNORE_ID    = -100\n",
    "MAX_LEN      = 1024"
   ],
   "id": "34e4e9e3348a2461",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And set up the prompt with prompt builders.",
   "id": "69e96d371276f716"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:08.301028Z",
     "start_time": "2025-05-22T22:01:08.299463Z"
    }
   },
   "cell_type": "code",
   "source": "sys_prompt = f\" You are an FM-5-0 assistant. Concisely answer the following question.\"",
   "id": "da0a0a467b6c851b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:08.359423Z",
     "start_time": "2025-05-22T22:01:08.357711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sys_role = \"system\"\n",
    "usr_role = \"user\"\n",
    "bot_role = \"assistant\""
   ],
   "id": "24d3b16c03e599c9",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "These are already in the tokenizer but being able to reference them will come in handy.",
   "id": "5d549a1b7d00bd2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:08.433306Z",
     "start_time": "2025-05-22T22:01:08.431468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bos_tok      = \"<|begin_of_text|>\"\n",
    "eot_id_tok   = \"<|eot_id|>\"\n",
    "start_hd_tok = \"<|start_header_id|>\"\n",
    "end_hd_tok   = \"<|end_header_id|>\"\n",
    "eot_tok      = \"<|end_of_text|>\""
   ],
   "id": "c6c917c375c565dd",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define some functions to process the data so we can train on it.",
   "id": "dcccbd03a0511c27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:08.496717Z",
     "start_time": "2025-05-22T22:01:08.494306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_prompt(sys, context, usr, ans=None):\n",
    "    prompt  = f\"{bos_tok}\"\n",
    "    prompt += f\"{start_hd_tok}{sys_role}{end_hd_tok}{context}{sys}{eot_id_tok}\"\n",
    "    prompt += f\"{start_hd_tok}{usr_role}{end_hd_tok}{usr}{eot_id_tok}\"\n",
    "    prompt += f\"{start_hd_tok}{bot_role}{end_hd_tok}\"\n",
    "\n",
    "    if ans is not None:\n",
    "        prompt += f\"{ans}{eot_id_tok}{eot_tok}\"\n",
    "\n",
    "    return prompt"
   ],
   "id": "80c26f524210411c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:08.555466Z",
     "start_time": "2025-05-22T22:01:08.553766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def row_to_prompt(row):\n",
    "    return {\"text\": build_prompt(sys_prompt, row['context'], row['question'], ans=row['answer'])}"
   ],
   "id": "23a4a0c2cba9230a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now process the data. I'll start with one sample to see how it's handled through the collator and evaluations.",
   "id": "34114a5a1f8a0bc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:22:33.844027Z",
     "start_time": "2025-05-22T22:22:33.838165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "splits  = raw_ds.train_test_split(TEST_PORTION, seed=42)\n",
    "sample = splits[\"train\"][100]\n",
    "print(sample)"
   ],
   "id": "27a063ac0592f5b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>The  division  tactical  command  post  will  control  the  air assault').\\n- b. (U) Signal. Describe the scheme of signal support, including location and movement of key signal nodes and critical electromagnetic spectrum considerations throughout the operation. State the primary, alternate, contingency, and emergency communications plan. Refer to Annex H (Signal) as required.\\n\\nACKNOWLEDGE: Include only if attachment is distributed separately from the base order.\\n\\n[Commander's last name]\\n\\n[Commander's rank]\\n\\nThe commander or authorized representative signs the original copy of the attachment. If the representative signs the original, add the phrase 'For the Commander.' The signed copy is the historical copy and remains in the headquarters' files.\\n\\n## OFFICIAL:\\n\\n[Authenticator's name]\\n\\n[Authenticator's position]\\n\\nUse only if the commander does not sign the original attachment. If the commander signs the original, no further authentication is required. If the commander does not sign, the signature of the preparing staff officer requires authentication and only the last name and rank of the commander appear in the signature block.\\n\\nATTACHMENTS: List lower-level attachment (appendixes, tabs, and exhibits). If a particular attachment is not used, place 'not used' beside the attachment number. Unit standard operating procedures will dictate attachment development and format. Common attachments include the following:\\n\\nAppendix 1 - Concept of Signal Support Overlay.\\n\\n- Appendix 2 - Department of Defense Information Network Operations.\\n- Appendix 3 - Network Transport and Information Services.\\n- Appendix 4 - Spectrum Management Operations.\\n- Appendix 5 - Communications Security.\\n\\nDISTRIBUTION: Show only if distributed separately from the base order or higher-level attachments.\\n\\n## [page number] [CLASSIFICATION]\\n\\nFigure E-8. Sample Annex H (Signal) format (continued)\\n\\n## ANNEX I (AIR AND MISSILE DEFENSE) FORMAT AND INSTRUCTIONS\\n\\n- E-43. This annex provides fundamental considerations, formats, and instructions for developing Annex I (Air and Missile Defense) to the base plan or order. This annex follows the five-paragraph attachment format.\\n- E-44. Commanders and staffs use Annex I (Air and Missile Defense) to describe how air defense supports the concept of operations described in the base plan or order. The supporting air defense artillery commander in  coordination  with  the You are an FM-5-0 assistant. Concisely answer the following question.<|eot_id|><|start_header_id|>user<|end_header_id|>What does Annex I (Air and Missile Defense) provide?<|eot_id|><|start_header_id|>assistant<|end_header_id|>This annex provides fundamental considerations, formats, and instructions for developing Annex I (Air and Missile Defense) to the base plan or order.<|eot_id|><|end_of_text|>\"}\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:57:18.042525Z",
     "start_time": "2025-05-22T22:57:18.038431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tok.add_bos_token = False\n",
    "tokenised = tok(\n",
    "    sample[\"text\"],\n",
    "    max_length=1024,\n",
    "    truncation=True,\n",
    ")\n",
    "\n",
    "print(\"IDS IN   :\", tokenised[\"input_ids\"][:40])\n",
    "print(\"MASK     :\", tokenised[\"attention_mask\"][:40])\n",
    "print(\"TOKENS IN:\", tok.convert_ids_to_tokens(tokenised[\"input_ids\"][:40]))\n",
    "print(\"TOKENS IN:\", tok.decode(tokenised[\"input_ids\"][:40], clean_up_tokenization_spaces=True))"
   ],
   "id": "484ebd44986702d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDS IN   : [128000, 128006, 9125, 128007, 791, 220, 13096, 220, 39747, 220, 3290, 220, 1772, 220, 690, 220, 2585, 220, 279, 220, 3805, 11965, 1861, 198, 12, 293, 13, 320, 52, 8, 28329, 13, 61885, 279, 13155, 315, 8450, 1862, 11, 2737]\n",
      "MASK     : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "TOKENS IN: ['<|begin_of_text|>', '<|start_header_id|>', 'system', '<|end_header_id|>', 'The', 'Ġ', 'Ġdivision', 'Ġ', 'Ġtactical', 'Ġ', 'Ġcommand', 'Ġ', 'Ġpost', 'Ġ', 'Ġwill', 'Ġ', 'Ġcontrol', 'Ġ', 'Ġthe', 'Ġ', 'Ġair', 'Ġassault', \"').\", 'Ċ', '-', 'Ġb', '.', 'Ġ(', 'U', ')', 'ĠSignal', '.', 'ĠDescribe', 'Ġthe', 'Ġscheme', 'Ġof', 'Ġsignal', 'Ġsupport', ',', 'Ġincluding']\n",
      "TOKENS IN: <|begin_of_text|><|start_header_id|>system<|end_header_id|>The  division  tactical  command  post  will  control  the  air assault').\n",
      "- b. (U) Signal. Describe the scheme of signal support, including\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "So far so good, we have the desired prompt being tokenized and it de-tokenizes properly. Now I'll check the collator. I'm looking for the entire prompt to be ignored up to the actual assistant response.",
   "id": "a87c780aa36c756"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:58:10.640596Z",
     "start_time": "2025-05-22T22:58:10.636852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "collator = DataCollatorForCompletionOnlyLM(\n",
    "    tokenizer            = tok,\n",
    "    instruction_template = f\"{start_hd_tok}{usr_role}{end_hd_tok}\",\n",
    "    response_template    = f\"{start_hd_tok}{bot_role}{end_hd_tok}\",\n",
    ")"
   ],
   "id": "26eadf5391bcfb6e",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:58:13.378385Z",
     "start_time": "2025-05-22T22:58:13.373645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch = collator([tokenised])\n",
    "for k,v in batch.items():\n",
    "    print(k, v.shape, v[0][:40])"
   ],
   "id": "e57d27eb89f8769e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([1, 583]) tensor([128000, 128006,   9125, 128007,    791,    220,  13096,    220,  39747,\n",
      "           220,   3290,    220,   1772,    220,    690,    220,   2585,    220,\n",
      "           279,    220,   3805,  11965,   1861,    198,     12,    293,     13,\n",
      "           320,     52,      8,  28329,     13,  61885,    279,  13155,    315,\n",
      "          8450,   1862,     11,   2737])\n",
      "attention_mask torch.Size([1, 583]) tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "labels torch.Size([1, 583]) tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100])\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First part looks good, all of the context that's injected is ignored.",
   "id": "688bac0f4d3c01a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T23:26:31.943179Z",
     "start_time": "2025-05-22T23:26:31.937799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for k,v in batch.items():\n",
    "    print(k, v.shape, v[0][-40:])"
   ],
   "id": "98f5ae98bf61a5a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([1, 583]) tensor([ 26777,    323,  68870,  16777,      8,   3493,     30, 128009, 128006,\n",
      "         78191, 128007,   2028,  54368,   5825,  16188,  38864,     11,  20447,\n",
      "            11,    323,  11470,    369,  11469,  89720,    358,    320,  26777,\n",
      "           323,  68870,  16777,      8,    311,    279,   2385,   3197,    477,\n",
      "          2015,     13, 128009, 128001])\n",
      "attention_mask torch.Size([1, 583]) tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "labels torch.Size([1, 583]) tensor([  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "          -100,   -100,   2028,  54368,   5825,  16188,  38864,     11,  20447,\n",
      "            11,    323,  11470,    369,  11469,  89720,    358,    320,  26777,\n",
      "           323,  68870,  16777,      8,    311,    279,   2385,   3197,    477,\n",
      "          2015,     13, 128009, 128001])\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And looks like the very end of this sample contains the actual tokens (non -100 values). I'll detokenize those to make sure the entire answer is included.",
   "id": "957784c237180b95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T23:28:38.586038Z",
     "start_time": "2025-05-22T23:28:38.583198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels = batch[\"labels\"][0].tolist()\n",
    "last_mask_index = len(labels) - 1 - labels[::-1].index(IGNORE_ID)\n",
    "masked_label = tok.decode(labels[last_mask_index + 1:], skip_special_tokens=True)\n",
    "print(masked_label)"
   ],
   "id": "10c6fccd1fc66606",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This annex provides fundamental considerations, formats, and instructions for developing Annex I (Air and Missile Defense) to the base plan or order.\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "With data processing nailed down, I can split the data into a training and testing dataset and prepare for training. To create a more robust training cycle that leverages all data, I would utilize 10-fold cross-validation with 2 folds set to testing data while tuning the hyperparameters. After I'm happy with the hyperparameters, I'll train using all the data. For this though, I'm just going to use some typical good values for the hyperparameters.",
   "id": "a8c3d3522a72c663"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:08.783031Z",
     "start_time": "2025-05-22T22:01:08.614450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "splits      = raw_ds.train_test_split(TEST_PORTION, seed=42)\n",
    "text_train  = splits[\"train\"]\n",
    "text_test   = splits[\"test\"]\n",
    "\n",
    "tok_test  = splits[\"test\"].map(\n",
    "    lambda batch: tok(batch[\"text\"], add_special_tokens=False, truncation=True, max_length=MAX_LEN, padding=False),\n",
    "    batched=True)\n",
    "tok_train = splits[\"train\"].map(\n",
    "    lambda batch: tok(batch[\"text\"], add_special_tokens=False, truncation=True, max_length=MAX_LEN, padding=False),\n",
    "    batched=True)"
   ],
   "id": "dd2c930fb43b7a9d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now we load the model and the LoRA adapter.\n",
    "\n",
    "Ideally this would be dead simple with SFTTrainer, but it doesn't support custom metrics yet (https://github.com/huggingface/trl/issues/862) so we have to do everything manually. I'm using gradient checkpointing just because I ran out of memory while training on my personal GPU."
   ],
   "id": "92666caf9905ad1e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:33.063487Z",
     "start_time": "2025-05-22T22:01:08.861866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "            BASE_MODEL,\n",
    "            cache_dir=CACHE_DIR,\n",
    "            gguf_file=GGUF_FILE,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.bfloat16)\n",
    "base_model.gradient_checkpointing_enable()"
   ],
   "id": "1f7946ddf8deeb4d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Converting and de-quantizing GGUF tensors...:   0%|          | 0/147 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9639f52c6c0418486fb4a828c28e4e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:01:33.131963Z",
     "start_time": "2025-05-22T22:01:33.081920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lora_cfg = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\")\n",
    "lora_model = get_peft_model(base_model, lora_cfg)\n",
    "lora_model.print_trainable_parameters()  # sanity check"
   ],
   "id": "7646caf1ac6cf7fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 851,968 || all params: 1,236,666,368 || trainable%: 0.0689\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Before training, I'll set up some metrics for evaluation.\n",
    "\n",
    " - F1: This is span-wise F1 (from SQUAD) shows how well the prediction and truth match if we treat them as a \"bag of tokens\".\n",
    " - Perplexity: I like to look at this over loss because you can interpret it as how \"confident\" the model is for the next token. E.g. a perplexity of ~2 means the model is considering bet\n",
    " - BERT Score: This is a good one to help understand how close the meaning of the output is to the label. Since it compares the BERT embeddings of the prediction and label, the embeddings of similar words are more closely aligned than disparate words.\n",
    "\n",
    "There are some others I would like to use to gain as much insight as possible, but I omitted for simplicity here."
   ],
   "id": "5fb597a4e9e1a0f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:02:45.390012Z",
     "start_time": "2025-05-22T22:02:06.633746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bert_metric   = evaluate.load(\"bertscore\", cache_dir=CACHE_DIR)\n",
    "squad_metric  = evaluate.load(\"squad\", cache_dir=CACHE_DIR)"
   ],
   "id": "53d37749346972df",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:02:47.660268Z",
     "start_time": "2025-05-22T22:02:47.649218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_preds) -> dict:\n",
    "    preds  = eval_preds.predictions\n",
    "    labels = eval_preds.label_ids\n",
    "    losses = eval_preds.losses\n",
    "\n",
    "    cleaned_labels = np.where(labels != IGNORE_ID, labels, tok.pad_token_id)\n",
    "    cleaned_preds  = np.where(preds  != IGNORE_ID, preds,  tok.pad_token_id)\n",
    "\n",
    "    decoded_preds  = tok.batch_decode(cleaned_preds.tolist(), skip_special_tokens=True)\n",
    "    decoded_labels = tok.batch_decode(cleaned_labels.tolist(), skip_special_tokens=True)\n",
    "\n",
    "    squad_preds = [\n",
    "        {\"id\": str(i), \"prediction_text\": p}\n",
    "        for i, p in enumerate(decoded_preds)\n",
    "    ]\n",
    "    squad_refs = [\n",
    "        {\n",
    "            \"id\": str(i),\n",
    "            \"answers\": {\"text\": [decoded_labels[i]], \"answer_start\": [0]}\n",
    "        }\n",
    "        for i in range(len(decoded_labels))\n",
    "    ]\n",
    "    squad_results = squad_metric.compute(\n",
    "        predictions=squad_preds,\n",
    "        references=squad_refs\n",
    "    )\n",
    "\n",
    "    bert_results = bert_metric.compute(\n",
    "        predictions=decoded_preds,\n",
    "        references=decoded_labels,\n",
    "        lang=\"en\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"perplexity\":      np.mean(np.exp(losses)),\n",
    "        \"bert_precision\":  np.mean(bert_results[\"precision\"]),\n",
    "        \"bert_recall\":     np.mean(bert_results[\"recall\"]),\n",
    "        \"bert_f1\":         np.mean(bert_results[\"f1\"]),\n",
    "        \"qa_f1\":           squad_results[\"f1\"],\n",
    "        \"exact_match\":     squad_results[\"exact_match\"],\n",
    "    }"
   ],
   "id": "4872268a6e5fdd6a",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "All that's left is to set up the training loop and train the model.",
   "id": "7364474cc18806ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:03:21.982330Z",
     "start_time": "2025-05-22T22:02:55.809454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir                  = MODEL_DIR,\n",
    "    per_device_train_batch_size = 2,\n",
    "    gradient_accumulation_steps = 32,\n",
    "    num_train_epochs            = 10,\n",
    "    learning_rate               = 2e-4,\n",
    "    logging_steps               = 1,\n",
    "    save_steps                  = 1,\n",
    "    save_total_limit            = 10,\n",
    "    neftune_noise_alpha         = 0.1,\n",
    "    bf16                        = True,\n",
    "    bf16_full_eval              = True,\n",
    "    save_strategy               = \"epoch\",\n",
    "    eval_strategy               = \"epoch\",\n",
    "    report_to                   = \"none\",\n",
    "    label_names                 = [\"labels\"],\n",
    "    metric_for_best_model       = \"eval_loss\",\n",
    "    load_best_model_at_end      = True,\n",
    "    eval_on_start               = True,\n",
    "    eval_accumulation_steps     = 10,\n",
    "    include_for_metrics         = [\"loss\"],\n",
    "    predict_with_generate       = True,\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStoppingCallback(\n",
    "    early_stopping_patience  = 1,\n",
    "    early_stopping_threshold = 0.001,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model           = lora_model,\n",
    "    args            = args,\n",
    "    train_dataset   = tok_train,\n",
    "    eval_dataset    = tok_test,\n",
    "    data_collator   = collator,\n",
    "    callbacks       = [early_stopping],\n",
    "    compute_metrics = compute_metrics,\n",
    ")"
   ],
   "id": "ba1335d4a0043888",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T22:11:49.591912Z",
     "start_time": "2025-05-22T22:03:30.149894Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "1396f499eeef5dca",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='None' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      None\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:07]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[19]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/transformers/trainer.py:2245\u001B[39m, in \u001B[36mTrainer.train\u001B[39m\u001B[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[39m\n\u001B[32m   2243\u001B[39m         hf_hub_utils.enable_progress_bars()\n\u001B[32m   2244\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2245\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2246\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2247\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2248\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2249\u001B[39m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2250\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/transformers/trainer.py:2472\u001B[39m, in \u001B[36mTrainer._inner_training_loop\u001B[39m\u001B[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[39m\n\u001B[32m   2469\u001B[39m \u001B[38;5;28mself\u001B[39m.control = \u001B[38;5;28mself\u001B[39m.callback_handler.on_train_begin(args, \u001B[38;5;28mself\u001B[39m.state, \u001B[38;5;28mself\u001B[39m.control)\n\u001B[32m   2471\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m args.eval_on_start:\n\u001B[32m-> \u001B[39m\u001B[32m2472\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskip_scheduler\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m   2474\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs_trained, num_train_epochs):\n\u001B[32m   2475\u001B[39m     epoch_dataloader = train_dataloader\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/transformers/trainer.py:3045\u001B[39m, in \u001B[36mTrainer._evaluate\u001B[39m\u001B[34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001B[39m\n\u001B[32m   3044\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_evaluate\u001B[39m(\u001B[38;5;28mself\u001B[39m, trial, ignore_keys_for_eval, skip_scheduler=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m-> \u001B[39m\u001B[32m3045\u001B[39m     metrics = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3046\u001B[39m     \u001B[38;5;28mself\u001B[39m._report_to_hp_search(trial, \u001B[38;5;28mself\u001B[39m.state.global_step, metrics)\n\u001B[32m   3048\u001B[39m     \u001B[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/transformers/trainer_seq2seq.py:197\u001B[39m, in \u001B[36mSeq2SeqTrainer.evaluate\u001B[39m\u001B[34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001B[39m\n\u001B[32m    195\u001B[39m \u001B[38;5;28mself\u001B[39m.gather_function = \u001B[38;5;28mself\u001B[39m.accelerator.gather\n\u001B[32m    196\u001B[39m \u001B[38;5;28mself\u001B[39m._gen_kwargs = gen_kwargs\n\u001B[32m--> \u001B[39m\u001B[32m197\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43meval_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/transformers/trainer.py:4154\u001B[39m, in \u001B[36mTrainer.evaluate\u001B[39m\u001B[34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001B[39m\n\u001B[32m   4151\u001B[39m start_time = time.time()\n\u001B[32m   4153\u001B[39m eval_loop = \u001B[38;5;28mself\u001B[39m.prediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.use_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.evaluation_loop\n\u001B[32m-> \u001B[39m\u001B[32m4154\u001B[39m output = \u001B[43meval_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4155\u001B[39m \u001B[43m    \u001B[49m\u001B[43meval_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4156\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mEvaluation\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   4157\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001B[39;49;00m\n\u001B[32m   4158\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# self.args.prediction_loss_only\u001B[39;49;00m\n\u001B[32m   4159\u001B[39m \u001B[43m    \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   4160\u001B[39m \u001B[43m    \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4161\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4162\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4164\u001B[39m total_batch_size = \u001B[38;5;28mself\u001B[39m.args.eval_batch_size * \u001B[38;5;28mself\u001B[39m.args.world_size\n\u001B[32m   4165\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_key_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_jit_compilation_time\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output.metrics:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DunedainAssessment/.venv/lib/python3.12/site-packages/transformers/trainer.py:4443\u001B[39m, in \u001B[36mTrainer.evaluation_loop\u001B[39m\u001B[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[39m\n\u001B[32m   4441\u001B[39m     eval_set_kwargs[\u001B[33m\"\u001B[39m\u001B[33mlosses\u001B[39m\u001B[33m\"\u001B[39m] = all_losses \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mloss\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m args.include_for_metrics \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   4442\u001B[39m     eval_set_kwargs[\u001B[33m\"\u001B[39m\u001B[33minputs\u001B[39m\u001B[33m\"\u001B[39m] = all_inputs \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33minputs\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m args.include_for_metrics \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m4443\u001B[39m     metrics = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4444\u001B[39m \u001B[43m        \u001B[49m\u001B[43mEvalPrediction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mall_preds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mall_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43meval_set_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4445\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4446\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m metrics \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   4447\u001B[39m     metrics = {}\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 14\u001B[39m, in \u001B[36mcompute_metrics\u001B[39m\u001B[34m(eval_preds)\u001B[39m\n\u001B[32m     11\u001B[39m decoded_labels = tok.batch_decode(cleaned_labels.tolist(), skip_special_tokens=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m     12\u001B[39m \u001B[38;5;66;03m# tok.padding_side = \"right\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m squad_preds = \u001B[43m[\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[43m    \u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mid\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mprediction_text\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m}\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdecoded_preds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     17\u001B[39m \u001B[43m\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m     18\u001B[39m squad_refs = [\n\u001B[32m     19\u001B[39m     {\n\u001B[32m     20\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mid\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mstr\u001B[39m(i),\n\u001B[32m   (...)\u001B[39m\u001B[32m     23\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(decoded_labels))\n\u001B[32m     24\u001B[39m ]\n\u001B[32m     25\u001B[39m squad_results = squad_metric.compute(\n\u001B[32m     26\u001B[39m     predictions=squad_preds,\n\u001B[32m     27\u001B[39m     references=squad_refs\n\u001B[32m     28\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/JetBrains/Toolbox/apps/pycharm/plugins/python-ce/helpers/pydev/_pydevd_bundle/pydevd_frame.py:755\u001B[39m, in \u001B[36mPyDBFrame.trace_dispatch\u001B[39m\u001B[34m(self, frame, event, arg)\u001B[39m\n\u001B[32m    753\u001B[39m \u001B[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001B[39;00m\n\u001B[32m    754\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m info.pydev_state == STATE_SUSPEND:\n\u001B[32m--> \u001B[39m\u001B[32m755\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    756\u001B[39m     \u001B[38;5;66;03m# No need to reset frame.f_trace to keep the same trace function.\u001B[39;00m\n\u001B[32m    757\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.trace_dispatch\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/JetBrains/Toolbox/apps/pycharm/plugins/python-ce/helpers/pydev/_pydevd_bundle/pydevd_frame.py:412\u001B[39m, in \u001B[36mPyDBFrame.do_wait_suspend\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    411\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdo_wait_suspend\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m412\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_args\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/JetBrains/Toolbox/apps/pycharm/plugins/python-ce/helpers/pydev/pydevd.py:1220\u001B[39m, in \u001B[36mPyDB.do_wait_suspend\u001B[39m\u001B[34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[39m\n\u001B[32m   1217\u001B[39m         from_this_thread.append(frame_id)\n\u001B[32m   1219\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._threads_suspended_single_notification.notify_thread_suspended(thread_id, stop_reason):\n\u001B[32m-> \u001B[39m\u001B[32m1220\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/JetBrains/Toolbox/apps/pycharm/plugins/python-ce/helpers/pydev/pydevd.py:1235\u001B[39m, in \u001B[36mPyDB._do_wait_suspend\u001B[39m\u001B[34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[39m\n\u001B[32m   1232\u001B[39m             \u001B[38;5;28mself\u001B[39m._call_mpl_hook()\n\u001B[32m   1234\u001B[39m         \u001B[38;5;28mself\u001B[39m.process_internal_commands()\n\u001B[32m-> \u001B[39m\u001B[32m1235\u001B[39m         \u001B[43mtime\u001B[49m\u001B[43m.\u001B[49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1237\u001B[39m \u001B[38;5;28mself\u001B[39m.cancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[32m   1239\u001B[39m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "A quick test to see if the model internalized any of the data or just learned how to copy from the context.",
   "id": "2e26578766a4c879"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "usr = \"What does CCIR stand for?\"\n",
    "context  = \"\"\n",
    "\n",
    "prompt =  build_prompt(sys_prompt, context, usr)\n",
    "\n",
    "inputs = tok(prompt, return_tensors=\"pt\").to(lora_model.device)\n",
    "out = lora_model.generate(**inputs, max_new_tokens=512, temperature=0.2)\n",
    "print(tok.decode(out[0][inputs.input_ids.shape[-1]:], skip_special_tokens=False))"
   ],
   "id": "47add3b7c5680270",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And now compare the LoRA model to the untrained one.",
   "id": "ff2c96d63947d422"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "chunks = []\n",
    "with open(CHUNKED_DATA, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        chunks.append(json.loads(line))"
   ],
   "id": "8ec6469fcab926bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "usr = \"What does CCIR stand for?\"\n",
    "context  = chunks[17]\n",
    "\n",
    "prompt =  build_prompt(sys_prompt, context, usr)\n",
    "\n",
    "inputs = tok(prompt, return_tensors=\"pt\").to(lora_model.device)"
   ],
   "id": "8fd1ba8500968744"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "lora_out = lora_model.generate(**inputs, max_new_tokens=512, temperature=0.2)\n",
    "print(tok.decode(out[0][inputs.input_ids.shape[-1]:], skip_special_tokens=False))"
   ],
   "id": "f2c150779960e2be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "base_out = base_model.generate(**inputs, max_new_tokens=512, temperature=0.2)\n",
    "print(tok.decode(out[0][inputs.input_ids.shape[-1]:], skip_special_tokens=False))"
   ],
   "id": "7c225b0e59af9916"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T21:50:31.270868Z",
     "start_time": "2025-05-25T21:50:31.249985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_model_path = MODEL_DIR / \"final\"\n",
    "lora_model.save_pretrained(final_model_path.as_posix())\n",
    "# tok.save_pretrained(\"ft-rag-qa\")"
   ],
   "id": "a1f912139eca0ddb",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lora_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mlora_model\u001B[49m.save_pretrained(MODEL_DIR / \u001B[33m\"\u001B[39m\u001B[33mfinal\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      2\u001B[39m \u001B[38;5;66;03m# tok.save_pretrained(\"ft-rag-qa\")\u001B[39;00m\n",
      "\u001B[31mNameError\u001B[39m: name 'lora_model' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9f1979465f12dba9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
